{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use some of the key concepts to create a neural network for image classification \n",
    "# of items of clothing. Step one will be to normalize the input images, \n",
    "# and we'll use NDArray operations to calculate the channel mean. \n",
    "# We'll create a function to evaluate the performance of networks on the data, \n",
    "# and construct a couple of different neural networks for image classification.\n",
    "\n",
    "# Import the required libraries\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet.gluon.data.vision import FashionMNIST\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /Users/alaaasfour/.mxnet/datasets/fashion-mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading /Users/alaaasfour/.mxnet/datasets/fashion-mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-labels-idx1-ubyte.gz...\n"
     ]
    }
   ],
   "source": [
    "# 1)--> Data (& NDArray Operations)\n",
    "# use the in-built dataset called FashionMNIST which is a variant of the commonly \n",
    "# used MNIST dataset.\n",
    "# Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 \n",
    "# examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated \n",
    "# with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for \n",
    "# the original MNIST dataset for benchmarking machine learning algorithms. \n",
    "# It shares the same image size and structure of training and testing splits.\n",
    "test_dataset = FashionMNIST(train=False).transform_first(transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd1114b9610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 123\n",
    "sample_data, sample_label = test_dataset[sample_idx]\n",
    "plt.imshow(sample_data[0].asnumpy()) # # 0 for first and only channel (since greyscale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# One improvement step before passing to the network is normalization: i.e. shifting and\n",
    "# scaling the pixel values so that they are zero-centred on average and have unit variance.\n",
    "\n",
    "# Methods of Normalization:\n",
    "# 1: pixelwise, where each \"pixel\" should have a unit normal distribution of values.\n",
    "# 2: channelwise, where each \"channel\" should have a unit normal distribution of values.\n",
    "\n",
    "# One of the first steps in the pixelwise approach is to calculate an 'average image'\n",
    "# from the dataset. Using a sample of 1024 images.\n",
    "test_dataloader = mx.gluon.data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "for data, label in test_dataloader:\n",
    "    break\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculate the 'average image'\n",
    "# param batch: batch of images in NCHW layout\n",
    "# type batch: mx.nd.NDArray\n",
    "# return: average image in CHW layout\n",
    "def get_average_image_from_batch(batch):\n",
    "    return (mx.nd.mean(batch, axis=0))\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd1116d4700>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_image = get_average_image_from_batch(data)\n",
    "assert average_image.shape == (1, 28, 28)\n",
    "plt.imshow(average_image[0].asnumpy()) # 0 for the first and only channel (greyscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the average image calculated above, we should implement a function to perform the \n",
    "# pixelwise normalization.\n",
    "# param sample: sample image in CHW layout\n",
    "# type sample: mx.nd.NDArray\n",
    "# param average_image: average image of the dataset in CHW layout\n",
    "# type average_image: mx.nd.NDArray\n",
    "# return: pixelwise normalized image in CHW layout\n",
    "\n",
    "def subtract_average_image(sample, average_image):\n",
    "    return sample-average_image\n",
    "    raise NotADirectoryError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd0f74660a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_sample_data = subtract_average_image(sample_data, average_image)\n",
    "assert normalized_sample_data.shape == (1, 28, 28)\n",
    "np.testing.assert_array_almost_equal(normalized_sample_data.asnumpy(), (sample_data - average_image).asnumpy())\n",
    "plt.imshow(normalized_sample_data[0].asnumpy()) # 0 for the first and only channel (since greyscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channelwise Normalization.\n",
    "# This function should return the average value for each channel across the images \n",
    "# of the batch of multi-channel inputs.\n",
    "# param batch: batch of images in NCHW layout\n",
    "# type batch: mx.nd.NDArray\n",
    "# return: channel averages in C layout\n",
    "# rtype: mx.nd.NDArray\n",
    "def get_channel_average_from_batch(batch):\n",
    "    return (mx.nd.mean(batch, axis=1, exclude=True))\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28757906\n"
     ]
    }
   ],
   "source": [
    "channel_average = get_channel_average_from_batch(data).asscalar()\n",
    "print(channel_average)\n",
    "assert isinstance(channel_average, np.float32)\n",
    "np.testing.assert_almost_equal(channel_average, 0.28757906, decimal=5)\n",
    "\n",
    "test_averages = mx.nd.array([1,2,3,4])\n",
    "test_input = mx.nd.reshape(test_averages, shape=(1,4,1,1)) * mx.nd.ones(shape=(10,4,25,25))\n",
    "test_channel_average = get_channel_average_from_batch(test_input)\n",
    "np.testing.assert_array_almost_equal(test_averages.asnumpy(), test_channel_average.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this channel average, we can use the Normalize transform to apply this \n",
    "# to all samples in our dataset as they are loaded\n",
    "channel_std = 0.31\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(channel_average, channel_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /Users/alaaasfour/.mxnet/datasets/fashion-mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading /Users/alaaasfour/.mxnet/datasets/fashion-mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FashionMNIST(train=True).transform_first(transform)\n",
    "test_dataset = FashionMNIST(train=False).transform_first(transform)\n",
    "train_dataloader = mx.gluon.data.DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
    "test_dataloader = mx.gluon.data.DataLoader(train_dataset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)--> Metrics\n",
    "# Here, we will implement a function to test the prediction quality of networks. Using\n",
    "# Accuracy as the evaluation metric.\n",
    "# The following functions takes a network and a dataloader (with test data) and returns an\n",
    "# MXNet Metric that has been updated with labels and predictions.\n",
    "# Calculate the accuracy of the network on the data given by the dataloader.\n",
    "# return: updated metric\n",
    "# rtype: mx.metric.EvalMetric\n",
    "from mxnet import metric\n",
    "def calculate_accuaracy(network, dataloader):\n",
    "    accuracy = metric.Accuracy()\n",
    "    for data, labels in tqdm(dataloader):\n",
    "        preds = network(data)\n",
    "        accuracy.update(labels = labels,preds= preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.08005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_network = mx.gluon.nn.Dense(units=10)\n",
    "test_network.initialize()\n",
    "metric = calculate_accuaracy(test_network, test_dataloader)\n",
    "print(metric.get())\n",
    "isinstance(metric, mx.metric.EvalMetric)\n",
    "assert metric.name == 'accuracy'\n",
    "assert metric.num_inst == 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)--> Network\n",
    "# Here, we will implement a couple of different image classification networks and train \n",
    "# them on the FashionMNIST dataset. \n",
    "def train(network, dataloader):\n",
    "    softmax_cross_entropy = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = mx.gluon.Trainer(network.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "    for data, label in tqdm(dataloader):\n",
    "        with mx.autograd.record():\n",
    "            output = network(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first model should be a sequential network with 3 layers.\n",
    "# The first layer should have 16 hidden units.\n",
    "# The second layer should have 8 hidden units.\n",
    "# The last layer should the correct number of output units for the classification task at hand.\n",
    "from mxnet.gluon import nn\n",
    "network = nn.Sequential()\n",
    "network.add(\n",
    "    nn.Dense(16, activation='relu'),\n",
    "    nn.Dense(8, activation='relu'),\n",
    "    nn.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(network, mx.gluon.nn.Sequential)\n",
    "assert len(network) == 3\n",
    "assert isinstance(network[0], mx.gluon.nn.Dense)\n",
    "assert network[0].act.name.endswith('relu')\n",
    "assert network[0].weight.shape[0] == 16\n",
    "assert isinstance(network[1], mx.gluon.nn.Dense)\n",
    "assert network[1].act.name.endswith('relu')\n",
    "assert network[1].weight.shape[0] == 8\n",
    "assert isinstance(network[2], mx.gluon.nn.Dense)\n",
    "assert network[2].act is None\n",
    "assert network[2].weight.shape[0] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the defined network, we should initialize its parameters using the Xavier method.\n",
    "initializer = mx.initializer.Xavier()\n",
    "network.initialize(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(initializer, mx.initializer.Xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (1024, 1, 28, 28)               0\n",
      "        Activation-1                    <Symbol dense1_relu_fwd>               0\n",
      "        Activation-2                                  (1024, 16)               0\n",
      "             Dense-3                                  (1024, 16)           12560\n",
      "        Activation-4                    <Symbol dense2_relu_fwd>               0\n",
      "        Activation-5                                   (1024, 8)               0\n",
      "             Dense-6                                   (1024, 8)             136\n",
      "             Dense-7                                  (1024, 10)              90\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 12786\n",
      "   Trainable params: 12786\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 12786\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# checking the network summary, the network has 12786 trainable parameters\n",
    "network.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy of the network on the data given by the dataloader\n",
    "# param network: network to be tested\n",
    "# type network: mx.gluon.Block\n",
    "# param dataloader: dataloader for test data\n",
    "# type datalaoder: mx.gluon.data.DataLoader\n",
    "# return updated metric\n",
    "# rtype: mx.metric.EvalMetric\n",
    "\n",
    "from mxnet import metric \n",
    "def calculate_accuracy(network, dataloader):\n",
    "    accuracy = metric.Accuracy()\n",
    "    for data, labels in tqdm(dataloader):\n",
    "        preds = network(data)\n",
    "        accuracy.update(labels = labels,preds = preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 71.64it/s]\n",
      "100%|██████████| 469/469 [00:05<00:00, 84.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.8136666666666666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the calculate_accuracy function to evaluate the performance of this architecture.\n",
    "train(network, train_dataloader)\n",
    "metric = calculate_accuaracy(network, test_dataloader)\n",
    "print(metric.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying different architecture that uses convolutional and max pooling layers.\n",
    "# We define another sequential network which has 5 layers in total\n",
    "# 1. Convolutional Layer (32 channels, 3x3 kernel and ReLU activation)\n",
    "# 2. Max Pooling Layer (2x2 kernel and 2x2 stride)\n",
    "# 3. Convolutional Layer (16 channels, 3x3 kernel and ReLU activation)\n",
    "# 4. Max Pooling Layer (2x2 kernel and 2x2 stride)\n",
    "# 5. Dense Layer (10 output units)\n",
    "network = nn.Sequential()\n",
    "network.add(\n",
    "    nn.Conv2D(32, (3,3), activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    nn.Conv2D(16, (3,3), activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    nn.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(network, mx.gluon.nn.Sequential)\n",
    "assert len(network) == 5\n",
    "assert isinstance(network[0], mx.gluon.nn.Conv2D)\n",
    "assert network[0].act.name.endswith('relu')\n",
    "assert network[0].weight.shape[0] == 32\n",
    "assert isinstance(network[1], mx.gluon.nn.MaxPool2D)\n",
    "assert isinstance(network[2], mx.gluon.nn.Conv2D)\n",
    "assert network[2].act.name.endswith('relu')\n",
    "assert network[2].weight.shape[0] == 16\n",
    "assert isinstance(network[3], mx.gluon.nn.MaxPool2D)\n",
    "assert isinstance(network[4], mx.gluon.nn.Dense)\n",
    "assert network[4].act is None\n",
    "assert network[4].weight.shape[0] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (1024, 1, 28, 28)               0\n",
      "        Activation-1                     <Symbol conv0_relu_fwd>               0\n",
      "        Activation-2                          (1024, 32, 26, 26)               0\n",
      "            Conv2D-3                          (1024, 32, 26, 26)             320\n",
      "         MaxPool2D-4                          (1024, 32, 13, 13)               0\n",
      "        Activation-5                     <Symbol conv1_relu_fwd>               0\n",
      "        Activation-6                          (1024, 16, 11, 11)               0\n",
      "            Conv2D-7                          (1024, 16, 11, 11)            4624\n",
      "         MaxPool2D-8                            (1024, 16, 5, 5)               0\n",
      "             Dense-9                                  (1024, 10)            4010\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 8954\n",
      "   Trainable params: 8954\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 8954\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# checking the network summary, the network has 8954 trainable parameters \n",
    "# (30% fewer parameter than the previous one)\n",
    "network.initialize(init=initializer)\n",
    "network.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the network\n",
    "# param network: network to be tested\n",
    "# type network: mx.gluon.Block\n",
    "# param dataloader: dataloader for test data\n",
    "# type dataloader: mx.gluon.data.DataLoader\n",
    "# return updated metric\n",
    "# rtype: mx.metric.EvalMetric\n",
    "\n",
    "from mxnet import metric\n",
    "def calculate_accuracy(network, dataloader):\n",
    "    accuracy = metric.Accuracy()\n",
    "    for data, labels in tqdm(dataloader):\n",
    "        preds = network(data)\n",
    "        accuracy.update(labels = labels,preds = preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:14<00:00, 32.53it/s]\n",
      "100%|██████████| 469/469 [00:10<00:00, 46.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.8418166666666667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally, evaluate the network performance\n",
    "train(network, train_dataloader)\n",
    "metric = calculate_accuracy(network, test_dataloader)\n",
    "print(metric.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
